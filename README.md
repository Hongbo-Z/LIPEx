# LIPEx
The fundamental approach to explaining machine learning models involves locally or globally approximating a model. Most current work in this field concentrates only on explaining the predicted class. However, gaining insight into the contributing factors for all potential classes at a particular test point, beyond just the predicted one, can offer valuable insights for machine learning and deep learning practitioners. This project proposes a perturbation-based multi-class explanation framework named **L**ocally **I**nterpretable **P**robabilistic **E**xplanation (LIPEx).

# How to use

# Example
## Text
[Text demo ](text_demo.pdf)
## Image
